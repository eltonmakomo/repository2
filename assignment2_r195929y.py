# -*- coding: utf-8 -*-
"""ASSIGNMENT2_R195929Y.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yt8BH2_RqHCdEEJACCYhEV12Ojq-qGhV
"""

#importing the required libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import seaborn as sns
from numpy import array
from sklearn.preprocessing import LabelEncoder 
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report

from google.colab import drive
drive.mount('/content/drive', force_remount =True)

Telco_customer_churn = pd.read_csv('/content/drive/My Drive/Assignment2/datasets_13996_18858_WA_Fn-UseC_-Telco-Customer-Churn.csv')

Telco_customer_churn.shape

Telco_customer_churn.head()

Telco_customer_churn.info(verbose=True)

Telco_customer_churn.describe()

Telco_customer_churn['Churn'].unique()

#1st indetifying Churnning Ratio
Telco_customer_churn['Churn'].value_counts().plot(kind ='barh', figsize =(8,6))
plt.xlabel('Count', labelpad=14)
plt.ylabel('Count of TARGET Variable per category', y = 1.02 );

100*Telco_customer_churn['Churn'].value_counts()/len(Telco_customer_churn['Churn'])

Telco_customer_churn['Churn'].value_counts()

#creating a copy of base data for manipulation and processing
Telco_df = Telco_customer_churn.copy()

#converting total charges to numeric data type
Telco_df.TotalCharges = pd.to_numeric(Telco_df.TotalCharges, errors ='coerce')
Telco_df.isnull().sum()   #checking missing values and finding the total

Telco_df.loc[Telco_df['TotalCharges'].isnull()== True]

#Removing missing values
Telco_df.dropna(how='any', inplace = True)

#calculating correlations
Telco_df.corr()

print(Telco_df.tenure.max())  #finding maximum months for Tenure

#therefore grouping into groups of 12, to get 6 groups
labels =['{0} - {1}'.format(i, i +11) for i in range( 1, 72, 12 )]
Telco_df['tenure_group']= pd.cut(Telco_df.tenure, range(1, 80, 12), right =False, labels=labels )

Telco_df['tenure_group'].value_counts()

Telco_df.drop(columns=['customerID', 'tenure'], axis= 1, inplace = True)
Telco_df.head()

for i, predictor in enumerate(Telco_df.drop(columns = ['Churn', 'TotalCharges', 'MonthlyCharges'])):
  plt.figure(i)
  sns.countplot(data= Telco_df, x= predictor, hue = 'Churn')

Telco_df['Churn'] = np.where(Telco_df.Churn == 'Yes', 1 , 0)

Telco_df_dummies = pd.get_dummies(Telco_df)
Telco_df_dummies.head()

sns.lmplot(data=Telco_df_dummies , x = 'MonthlyCharges', y ='TotalCharges', fit_reg = False)

Mth = sns.kdeplot(Telco_df_dummies.MonthlyCharges[(Telco_df_dummies["Churn"] == 0)],
                  color ='Red',shade =True)
Mth = sns.kdeplot(Telco_df_dummies.MonthlyCharges[(Telco_df_dummies['Churn']== 1)],
                  ax = Mth, color ='Blue', shade =True)
Mth.legend(['No Churn', 'Churn'], loc ='upper right')
Mth.set_ylabel('Density')
Mth.set_xlabel('Monthly Charges')
Mth.set_title('Monthly charges churn')

plt.figure(figsize =(20,8))
Telco_df_dummies.corr()['Churn'].sort_values(ascending =False).plot(kind ='bar')

df = Telco_df_dummies.copy()

"""Building The Model"""

from sklearn.model_selection import train_test_split

#creating X and Y Variables
x = df.drop('Churn', axis =1)
print(x)

#creating X and Y variables
y = df['Churn']
y

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size =0.2)

"""**Building The XGBOOST MODEL**"""

import xgboost as xgb
from xgboost import XGBClassifier
xgb_model = xgb.XGBClassifier(max_depth=5, learning_rate=0.08, objective= 
            'binary:logistic',n_jobs=-1).fit(x_train, y_train)
xgb_model

#Accuracy of XGBOOST on training set
xgb_model.score(x_train, y_train)

#Accuracy of XGBOOST on test set and AUC
y_pred = xgb_model.predict(x_test)
score = accuracy_score(y_test, y_pred)
score

print(classification_report(y_test, y_pred))

from xgboost import plot_importance
fig, ax = plt.subplots(figsize=(10,8))
plot_importance(xgb_model, ax=ax)

from sklearn.externals import joblib

#params = {"objective":"binary:logistic",'colsample_bytree': 0.3,'learning_rate': 0.1,
#                'max_depth': 5, 'alpha': 10}
#classification = xgb.XGBClassifier(**params)

joblib.dump(classification, 'AI_model.pkl')